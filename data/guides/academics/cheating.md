---
title: "How to Cheat"
---

# Don't.

Furthermore, most code submission portals professors use run an automatic code comparison tool. If you and another student copied code from one another the professor will automatically get a report.

Also be careful to make your submission code private. If you put it on a public repository and someone copies your code without your knowledge or approval, you may still be held accountable and docked points.

# On AI

Artificial Intelligence is even worse than copying from a friend. It actively hurts you, and not just academically.

It's a slippery slope. Getting the correct answer without trying at all is addictive. At least when you copy from a friend, you have to go through the awkward or guilty process of asking them for their answers. It shouldn't feel good. Asking ChatGPT, or Claude, or Gemini, or even your custom GPT that you "configured so it's just helping, I promise" is hurting you. It's allowing you to get the result you want, with minimal effort. Once or twice it won't feel so bad, but as you keep doing it, you'll find that it's all you know how to do. You'll stop being able to research things without AI, or write without the AI checking at all for you (especially if by checking you mean plugging it in and asking for a "better looking version").

Beyond hurting yourself, it's hurting those that you try to pass your shitty AI slop off as real work to. Don't believe me? How about you read this two-page essay generated entirely by ChatGPT about why you should stop using AI:

> Artificial intelligence tools have rapidly entered classrooms, study spaces, and dorm rooms, reshaping how students read, write, and think. Systems capable of generating essays, solving equations, and summarizing complex texts promise efficiency and accessibility, but they also raise serious concerns about learning, intellectual development, and academic integrity. While AI can function as a supplemental educational aid, this essay argues that students should significantly limit or stop using AI for their schoolwork because habitual reliance undermines critical thinking, weakens literacy skills, affects mental health, and may ultimately reduce long-term academic and professional success.
>
> The primary reason students should stop relying on AI is that education is fundamentally about developing cognitive skills, not merely producing correct or polished outputs. Writing an essay, solving a problem, or analyzing a text requires students to engage in reasoning, synthesis, and reflection. When AI performs these tasks, students bypass the mental effort that produces learning. Educational psychologists have long emphasized that durable learning depends on effortful processing and productive struggle. When students outsource thinking to AI, they may complete assignments faster, but they practice thinking less, which weakens the very skills higher education is designed to cultivate.
>
> There are, however, legitimate advantages to AI use in academic contexts. AI tools can provide explanations, examples, and feedback that resemble tutoring, which may be particularly helpful for students who lack access to academic support. Research suggests that AI-assisted feedback can improve short-term writing quality and help students understand unfamiliar concepts more quickly. For students with learning differences or language barriers, AI can also improve accessibility by offering alternative explanations and scaffolding. These benefits demonstrate that AI is not inherently harmful, but rather context-dependent.
>
> Despite these advantages, the drawbacks of using AI for schoolwork are substantial. One of the most significant risks is skill erosion. Writing proficiency, critical reading, and analytical reasoning improve through repeated practice. When AI consistently drafts essays or generates answers, students lose opportunities to strengthen these skills. Over time, this can result in graduates who perform well on assignments but struggle to articulate ideas independently. Additionally, academic integrity becomes a concern, as many institutions classify uncredited AI-generated work as plagiarism. Even when policies are ambiguous, submitting work that does not reflect one’s own thinking undermines the purpose of assessment and devalues academic credentials.
>
> The mental health effects of relying on AI for all academic work are also important to consider. Students who habitually use AI may experience reduced self-efficacy, or confidence in their own abilities. Psychological research links self-efficacy to motivation, persistence, and resilience. When students believe they cannot succeed without AI, they may experience increased anxiety when faced with tasks that require independent thinking, such as exams or in-class writing. Rather than alleviating stress, AI dependence can create a fragile sense of competence that collapses when external support is unavailable.
>
> Furthermore, constant AI use may alter students’ attention and motivation. AI encourages immediacy, offering instant answers that reduce tolerance for ambiguity and sustained effort. Over time, this can make challenging tasks feel more overwhelming and discourage deep engagement. Some students may also feel pressure to use AI because peers are doing so, which can contribute to guilt, stress, and a sense of inauthenticity about their academic achievements. These psychological effects suggest that AI use is not merely a technical issue, but a developmental one.
>
> Metrics on the success of individuals who use AI reveal a mixed picture. Studies indicate that students who use AI tools for drafting and revision often achieve higher short-term grades and produce more polished assignments. However, longitudinal research suggests that heavy AI users show smaller gains in writing ability and critical thinking over time compared to students who engage directly with their work. Knowledge retention also appears weaker when students rely on AI-generated explanations rather than constructing understanding themselves. These findings imply that while AI may boost performance metrics in the short term, it does not reliably support long-term learning outcomes.
>
> Academic research has also begun to examine AI’s relationship to the growing literacy crisis in the United States. National assessments show declining reading and writing proficiency among students, particularly in secondary education. Scholars warn that widespread AI use may exacerbate this trend by reducing the amount of reading, writing, and revision students perform independently. Literacy is not simply the ability to produce text, but the ability to comprehend, evaluate, and communicate ideas effectively. When AI performs these tasks, students lose essential practice that supports literacy development.
>
> In addition, cognitive science research on “cognitive offloading” suggests that relying on external tools for thinking tasks can weaken internal cognitive structures if used excessively. While tools have always played a role in learning, AI differs in that it performs higher-order cognitive functions, such as argument construction and synthesis. If students routinely delegate these functions to machines, they may graduate with underdeveloped analytical abilities, which has implications not only for academics but for civic engagement and professional competence.
>
> In conclusion, although artificial intelligence offers real benefits as a supplementary educational tool, its habitual use for schoolwork poses serious risks. Overreliance on AI can undermine critical thinking, erode literacy skills, negatively affect mental health, and weaken long-term learning outcomes. Education is meant to challenge students to think, struggle, and grow. When AI replaces these processes rather than supporting them, it compromises the core mission of schooling. For these reasons, students should limit or stop using AI for academic work and instead engage directly with the intellectual labor that fosters genuine learning and personal development.

Did you skip right to the end? Maybe you read the first few sentences, thought "this is chatted" and moved on? Hmm. I wonder what your peers and professors will think when they see AI-generated work that you submit?
